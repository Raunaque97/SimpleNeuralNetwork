{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def innitializeParams(dims,activations):\n",
    "    params={}\n",
    "    params['L']=len(activations)+1\n",
    "    for l in range(1,len(dims)):\n",
    "        params['W'+str(l)]=np.random.randn(dims[l],dims[l-1])/np.sqrt(dims[l-1])  #Xavier initialization\n",
    "        params['b'+str(l)]=np.random.randn(dims[l],1)/np.sqrt(dims[l-1])\n",
    "        params['layer'+str(l)+'activationType']=activations[l-1]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activationFunc(X,activationType):\n",
    "    \n",
    "    if activationType == \"relu\":\n",
    "        Y=np.maximum(X,0)\n",
    "    elif activationType == \"sigmoid\":\n",
    "        Y=(np.tanh(X/2)+1)/2\n",
    "    elif activationType == \"tanh\":\n",
    "        Y=np.tanh(X)\n",
    "    elif activationType == \"linear\":\n",
    "        Y=X\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activationGrad(X,activationType):\n",
    "    \n",
    "    if activationType == \"relu\":\n",
    "        Y=(X>0)*1.0 # *1.0 converts bool to float\n",
    "    elif activationType == \"sigmoid\":\n",
    "        Y=(1.0 - np.square(np.tanh(X)))/4\n",
    "    elif activationType == \"tanh\":\n",
    "        Y=1.0 - np.square(np.tanh(X))\n",
    "    elif activationType == \"linear\":\n",
    "        Y=X/X\n",
    "        \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPass(X,params,dropProbs=None):\n",
    "    cache={}\n",
    "    L=params['L']\n",
    "    A_prev = X\n",
    "    cache['A0']=X\n",
    "    for l in range(1,L):\n",
    "        Zl = np.dot(params['W'+str(l)],A_prev) + params['b'+str(l)]\n",
    "        Al = activationFunc(Zl,params['layer'+str(l)+'activationType'])\n",
    "        if dropProbs is not None:\n",
    "            Dl = np.random.rand(*Al.shape)\n",
    "            Dl = (Dl <= dropProbs[l-1])\n",
    "            Al = ( Al*Dl )/dropProbs[l-1]\n",
    "            cache['D'+str(l)] = Dl\n",
    "            \n",
    "        cache['Z'+str(l)] = Zl\n",
    "        cache['A'+str(l)] = Al\n",
    "        A_prev = Al\n",
    "    y=A_prev\n",
    "    \n",
    "    return y,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeCost(Y,y,params,cost='mse',regularization='none',lamda=0.01):\n",
    "    m=y.shape[1]\n",
    "    if cost=='mse':\n",
    "        Loss = np.sum(np.square(Y-y))/(2*m)\n",
    "    elif cost=='cross-entropy':\n",
    "        logprobs = np.multiply(-np.log(y),Y) + np.multiply(-np.log(1 - y), 1 - Y)\n",
    "        Loss = (1./m)* np.nansum(logprobs)\n",
    "    \n",
    "    #regularisations\n",
    "    L=params['L']\n",
    "    for l in range(1,L):\n",
    "        if regularization=='L2':\n",
    "            Loss = Loss + lamda*np.sum(np.square(params['W'+str(l)]))/(2*m)\n",
    "        elif regularization=='L1':\n",
    "            Loss = Loss + lamda*np.sum(np.abs(params['W'+str(l)]))/(2*m)\n",
    "    return Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradCost(Y,y,cost='mse'):    #depends on relgularizaton but will cancell anyways\n",
    "    if cost=='mse':\n",
    "        dy = y-Y\n",
    "    elif cost=='cross-entropy':\n",
    "        dy = (y-Y)/(y*(1-y))\n",
    "    return dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwardPass(Y,y,params,cache,dropProbs=None,cost='mse',regularization='none',lamda=0.01):\n",
    "    \n",
    "    dAl = GradCost(Y,y,cost)\n",
    "    L=params['L']\n",
    "    m=Y.shape[1]\n",
    "    grads={}\n",
    "    for l in reversed(range(1,L)):\n",
    "        dZl = dAl*activationGrad(cache['Z'+str(l)],params['layer'+str(l)+'activationType'])\n",
    "        grads['dW'+str(l)] = np.dot(dZl,cache['A'+str(l-1)].T)/m\n",
    "        grads['db'+str(l)] = np.sum(dZl,axis=1,keepdims=True)/m\n",
    "        \n",
    "        if regularization=='L2':\n",
    "            grads['dW'+str(l)] = grads['dW'+str(l)] + (lamda/m)*params['W'+str(l)]\n",
    "        elif regularization=='L1':\n",
    "            grads['dW'+str(l)] = grads['dW'+str(l)] + (lamda/m)*np.sign(params['W'+str(l)])\n",
    "        dAl = np.dot(params['W'+str(l)].T,dZl)\n",
    "        if dropProbs is not None:\n",
    "            dAl = ( dAl*params['D'+str(l)] )/dropProbs[l-1]\n",
    "    return grads  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParams(params,grads,learningRate,optimizer='gd',beta=0.9,beta1=.9,beta2=.999,eps=1e-10):\n",
    "    L=params['L']\n",
    "    if optimizer == 'gradientDecent' or optimizer=='gd':\n",
    "        for l in range(1,L):\n",
    "            params['W'+str(l)] = params['W'+str(l)] - learningRate*grads['dW'+str(l)]\n",
    "            params['b'+str(l)] = params['b'+str(l)] - learningRate*grads['db'+str(l)]\n",
    "        \n",
    "    elif optimizer=='momentum':            \n",
    "        for l in range(1,L):\n",
    "            if ('vdW'+str(l)) not in params:    #first time only\n",
    "                params['vdW'+str(l)]=np.zeros(params['W'+str(l)].shape)\n",
    "                params['vdb'+str(l)]=np.zeros(params['b'+str(l)].shape)\n",
    "            #update velocity\n",
    "            params['vdW'+str(l)] = beta*params['vdW'+str(l)] + (1-beta)*grads['dW' + str(l)]\n",
    "            params['vdb'+str(l)] = beta*params['vdb'+str(l)] + (1-beta)*grads['db' + str(l)]\n",
    "        \n",
    "            params['W'+str(l)] = params['W'+str(l)] - learningRate*params['vdW'+str(l)]\n",
    "            params['b'+str(l)] = params['b'+str(l)] - learningRate*params['vdb'+str(l)]\n",
    "        \n",
    "    elif optimizer=='rmsprop':\n",
    "        for l in range(1,L):\n",
    "            if ('sdW'+str(l)) not in params:    #first time only\n",
    "                params['sdW'+str(l)]=np.zeros(params['W'+str(l)].shape)\n",
    "                params['sdb'+str(l)]=np.zeros(params['b'+str(l)].shape)\n",
    "            #update sq of magnitude of grads\n",
    "            params['sdW'+str(l)] = beta*params['sdW'+str(l)] + (1-beta)*np.square(grads['dW' + str(l)])\n",
    "            params['sdb'+str(l)] = beta*params['sdb'+str(l)] + (1-beta)*np.square(grads['db' + str(l)])\n",
    "            \n",
    "            params['W'+str(l)] = params['W'+str(l)] - learningRate*grads['dW'+str(l)]/np.sqrt(params['sdW'+str(l)]+eps)\n",
    "            params['b'+str(l)] = params['b'+str(l)] - learningRate*grads['db'+str(l)]/np.sqrt(params['sdb'+str(l)]+eps)\n",
    "        \n",
    "    elif optimizer=='adam':\n",
    "        for l in range(1,L):\n",
    "            if ('vdW'+str(l)) not in params:    #first time only  for 'bias correction' \n",
    "                params['vdW'+str(l)]=grads['dW' + str(l)]\n",
    "                params['vdb'+str(l)]=grads['db' + str(l)]\n",
    "                params['sdW'+str(l)]=np.square(grads['dW' + str(l)])\n",
    "                params['sdb'+str(l)]=np.square(grads['db' + str(l)])\n",
    "            else:\n",
    "                params['vdW'+str(l)] = beta*params['vdW'+str(l)] + (1-beta)*grads['dW' + str(l)]\n",
    "                params['vdb'+str(l)] = beta*params['vdb'+str(l)] + (1-beta)*grads['db' + str(l)]\n",
    "                params['sdW'+str(l)] = beta*params['sdW'+str(l)] + (1-beta)*np.square(grads['dW' + str(l)])\n",
    "                params['sdb'+str(l)] = beta*params['sdb'+str(l)] + (1-beta)*np.square(grads['db' + str(l)])\n",
    "            \n",
    "            params['W'+str(l)] = params['W'+str(l)] - learningRate*params['vdW'+str(l)]/np.sqrt(params['sdW'+str(l)]+eps)\n",
    "            params['b'+str(l)] = params['b'+str(l)] - learningRate*params['vdb'+str(l)]/np.sqrt(params['sdb'+str(l)]+eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X,Y,params,steps,learningRate,optimizer='gd',cost='mse',regularization='none',lamda=0.01,dropProbs=None,showCost=False):\n",
    "    Cost = []\n",
    "    for i in range(steps):\n",
    "        y,cache = forwardPass(X,params,dropProbs)\n",
    "        if showCost==True:\n",
    "            if i%200==0:\n",
    "                print('step '+ str(i)+':'+str(ComputeCost(Y,y,params,cost,regularization,lamda)))\n",
    "            Cost.append(ComputeCost(Y,y,params,cost,regularization,lamda))\n",
    "            \n",
    "        grads = backwardPass(Y,y,params,cache,dropProbs,cost)\n",
    "        updateParams(params,grads,learningRate,optimizer)\n",
    "    if showCost==True:\n",
    "        plt.plot(np.linspace(1,steps,steps),Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(X):\n",
    "    mu = np.mean(X,axis=1,keepdims=True)\n",
    "    sigma = np.sqrt(np.mean( np.square(X-mu),axis=1,keepdims=True ))\n",
    "    X=(X-mu)/(sigma + 1e-10)\n",
    "    return X,mu,sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0:1.17757892767\n",
      "step 200:0.290547597826\n",
      "step 400:0.0902854396388\n",
      "step 0:1.39223616719\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'D2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-c5b575949163>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXhat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshowCost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregularization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXhat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gd'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshowCost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropProbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregularization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXhat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshowCost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregularization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-e2d98ffe145a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X, Y, params, steps, learningRate, optimizer, cost, regularization, lamda, dropProbs, showCost)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mCost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mComputeCost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregularization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackwardPass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropProbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mupdateParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearningRate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshowCost\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-f768e7577a61>\u001b[0m in \u001b[0;36mbackwardPass\u001b[0;34m(Y, y, params, cache, dropProbs, cost, regularization, lamda)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mdAl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdZl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdropProbs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mdAl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mdAl\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'D'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdropProbs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'D2'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f12cf8518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.random.rand(1,200)*6 -3\n",
    "Y = X**3/9 - X**2/6 - X + 0.5\n",
    "\n",
    "params = innitializeParams([1,16,1],['relu','linear'])\n",
    "params_t = params.copy()\n",
    "Xhat,_,_ = normalise(X)\n",
    "train(Xhat,Y,params,500,0.001,optimizer='adam',showCost=True,cost='mse',regularization='none')\n",
    "params = params_t.copy()\n",
    "train(Xhat,Y,params,500,0.001,optimizer='gd',showCost=True,cost='mse',dropProbs=[1,.8],regularization='none')\n",
    "params = params_t.copy()\n",
    "train(Xhat,Y,params,500,0.001,optimizer='rmsprop',showCost=True,cost='mse',regularization='L2')\n",
    "\n",
    "y,_ = forwardPass(Xhat,params)\n",
    "# plt.scatter(X,Y)\n",
    "# plt.scatter(X,y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
